{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of $q_0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "# needed imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the likelihood \n",
    "$$\\mathcal{L}(y|\\mu+b,\\vec{\\chi}) = \\frac{e^{-(\\mu+b)}(\\mu+b)^y}{y!}\\frac{e^{-\\frac{(\\mu-\\mu_0)^2}{2\\sigma_\\mu^2}}}{\\sqrt{2\\pi\\sigma_\\mu^2}}\\frac{e^{-\\frac{(b-b_0)^2}{2\\sigma_b^2}}}{\\sqrt{2\\pi\\sigma_b^2}}$$\n",
    "Which gives (keeping only \"interesting terms\")\n",
    "$$\\ell(\\mu,b) = -(\\mu+b)+y\\ln(\\mu+b) - \\frac{1}{2}\\left(\\frac{\\mu-\\mu_0}{\\sigma_\\mu}\\right)^2 - \\frac{1}{2} \\left(\\frac{b-b_0}{\\sigma_b}\\right)^2$$\n",
    "Studying the case for $\\sigma_s\\rightarrow\\infty$ the third term above becomes zero. From this we can find the MLEs for two cases.\n",
    "\n",
    "First, finding $\\hat\\mu$, which is done by setting $\\frac{\\partial\\ell(\\mu,b)}{\\partial\\mu}=0$, this gives us $\\hat\\mu = y - b_0$. Furthermore we can find $\\hat b$ by setting $\\frac{\\partial\\ell(\\hat\\mu,b)}{\\partial b}=0$, giving $\\hat b = b_0$\n",
    "\n",
    "Then for the second case, the null hypothesis we find $\\hat{\\hat b}$ by setting $\\frac{\\partial\\ell(0,b)}{\\partial b}=0$, this yields $\\hat{\\hat{b}} =\\frac{b_0-\\sigma_b^2+\\sqrt{(b_0-\\sigma_b^2)^2+4y\\sigma_b^2}}{2}$ \n",
    "\n",
    "Using these values for the likelihood ratio test statistics gives us\n",
    "\n",
    "$$\n",
    "q_0 = -2[\\ell(s=0,\\hat{\\hat b}) - \\ell(\\hat s, \\hat b)]\n",
    "$$\n",
    "Giving \n",
    "$$\n",
    "q_0 = 2(y\\ln\\frac{y}{\\hat{\\hat b}} + \\hat{\\hat b} - y) + \\left(\\frac{\\hat{\\hat b} -b_0}{\\sigma_b}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(mu, b, y, b_0, db):\n",
    "    ell = -(mu+b) + y*np.log(mu+b) -0.5*((b-b_0)/db)**2\n",
    "    return ell\n",
    "\n",
    "def test_Stat_null(y, b_hhat, b_0, db):\n",
    "    q_0 = 2*(y*np.log(y/b_hhat)+b_hhat - y) + ((b_hhat-b_0)/db)**2\n",
    "    return q_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the asympotics approximation of Brazzale et al we start by defining the likelihood root\n",
    "\n",
    "$$\n",
    "r(\\mu) = sign(\\hat\\mu-\\mu)\\sqrt{2(\\ell_p(\\hat\\mu, \\hat b) - \\ell_p(\\mu, \\hat{\\hat b}))} \n",
    "$$\n",
    "where $\\ell_p(\\mu) = \\ell(\\mu,\\hat{\\hat b})$ is the profile log likelihood. For our purposes we (should) have that\n",
    "$$\n",
    "r(0) = \\sqrt{q_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db):\n",
    "    ell_p_hat = log_likelihood(mu_hat, b_hat, y, b_0, db)\n",
    "    ell_p = log_likelihood(mu, b_hhat, y, b_0, db)\n",
    "    r = np.sign(mu_hat- mu)*np.sqrt(2*(ell_p_hat-ell_p))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First order approximation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we have the first order modification of the likelihood root (NB when the dimension of $\\mu$ is 1, which is the case here)\n",
    "\\begin{equation}\n",
    "    r^*(\\mu) = r(\\mu) + \\frac{1}{r(\\mu)}\\log\\left(\\frac{q(\\mu)}{r(\\mu)}\\right)\n",
    "\\end{equation}\n",
    "where\n",
    "$$\n",
    "q(\\mu) = t(\\mu) = \\sqrt{j_p(\\hat\\mu)} (\\hat\\mu - \\mu)\n",
    "$$\n",
    "is the Wald statistic, or\n",
    "$$\n",
    "q(\\mu) = s(\\mu) = \\sqrt{j_p(\\hat\\mu)}^{-1}\\frac{\\partial\\ell_p(\\mu)}{\\partial\\mu}\n",
    "$$\n",
    "is the score statistic. And where \n",
    "$$\n",
    "j_p(\\mu) = -\\frac{\\partial^2\\ell_p(\\mu)}{\\partial\\mu^2}\n",
    "$$\n",
    "is the observed information function. \n",
    "\n",
    "For our purposes, we have that \n",
    "$$\n",
    "\\frac{\\partial\\ell_p(\\mu)}{\\partial\\mu} = -1 + \\frac{y}{\\mu + \\hat{\\hat b}}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "j_p(\\mu) = -\\frac{\\partial^2\\ell_p(\\mu)}{\\partial\\mu^2} = \\frac{y}{(\\mu + \\hat{\\hat b})^2}\n",
    "$$\n",
    "\n",
    "The first order modification works models that are part the exponential family (or transformation family) making it a good approximation. Which the model we are studying in this notebook (or generally in HEP) is not. Meaning that this is not a good \"upgrade\" of the asymptotic for our purposes, as we shall soon see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_func(mu, b_hatt, y):\n",
    "    j = y/(mu+b_hatt)**2\n",
    "    return j\n",
    "\n",
    "def wald(mu_hat, mu, b_hatt, y, b_hat, db):\n",
    "    j = info_func(mu_hat, b_hatt, y)\n",
    "    t = np.sqrt(j)*(mu_hat-mu)*np.sqrt(  np.abs(y/(mu_hat + b_hat)**2 +1/db**2)/np.abs(y/(mu + b_hatt)**2 +1/db**2)   )\n",
    "    return t\n",
    "\n",
    "def score(mu_hat, mu, b_hatt, y):\n",
    "    j = info_func(mu_hat, b_hatt, y)\n",
    "    s = np.sqrt(1/j)*( -1 + y/(mu+b_hatt))\n",
    "    return s\n",
    "\n",
    "def modified_likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db, doWald=True):\n",
    "    r_mu = likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db)\n",
    "    if doWald == True:\n",
    "        q_mu = wald(mu_hat, mu, b_hhat, y, b_hat, db)\n",
    "    else: \n",
    "        q_mu = score(mu_hat, mu, b_hhat, y)\n",
    "    return r_mu + (1 / r_mu) * np.log(q_mu / r_mu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for an example using $y=3$, $b_0=0.78$ and $\\sigma_b=0.18$, first we compare that indeed $r(0)=\\sqrt q_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8477368150191664\n",
      "1.8477368150191662\n"
     ]
    }
   ],
   "source": [
    "y_obs = 3\n",
    "b_0 = 0.78\n",
    "sigma_b = 0.18\n",
    "\n",
    "mu_hat = y_obs - b_0\n",
    "b_hatt = (b_0-sigma_b**2+np.sqrt((b_0-sigma_b**2)**2+4*y_obs*(sigma_b**2)))/2\n",
    "b_hat = b_0\n",
    "\n",
    "r = likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b)\n",
    "\n",
    "q_0 = test_Stat_null(y_obs, b_hatt, b_0, sigma_b)\n",
    "\n",
    "print(r)\n",
    "print(np.sqrt(q_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check all the modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_s = modified_likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b) # Wald\n",
    "r_ss = modified_likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b, doWald=False) # Score\n",
    "r_mp = likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs+0.5, b_0, sigma_b) # Mid-p\n",
    "r_s_mp = modified_likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs+0.5, b_0, sigma_b)\n",
    "r_ss_mp = modified_likelihood_root(0, mu_hat, b_hat, b_hatt, y_obs+0.5, b_0, sigma_b, doWald=False)\n",
    "\n",
    "\n",
    "r_sf = stats.norm.sf(r, loc=0)\n",
    "r_star_sf = stats.norm.sf(r_s, loc=0)\n",
    "r_stars_sf = stats.norm.sf(r_ss, loc=0)\n",
    "r_sf_mp = stats.norm.sf(r_mp, loc=0)\n",
    "r_star_sf_mp = stats.norm.sf(r_s_mp, loc=0)\n",
    "r_stars_sf_mp = stats.norm.sf(r_ss_mp, loc=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True value</th>\n",
       "      <th>r</th>\n",
       "      <th>r* Wald</th>\n",
       "      <th>r* score</th>\n",
       "      <th>Mid-P r</th>\n",
       "      <th>Mid-P r* Wald</th>\n",
       "      <th>Mid-P r* score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>0.027993</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Significance</th>\n",
       "      <td>1.9400</td>\n",
       "      <td>1.847737</td>\n",
       "      <td>1.604981</td>\n",
       "      <td>2.319975</td>\n",
       "      <td>2.159381</td>\n",
       "      <td>1.911152</td>\n",
       "      <td>2.552854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              True value         r   r* Wald  r* score   Mid-P r  \\\n",
       "p-value           0.0264  0.032320  0.054249  0.010171  0.015410   \n",
       "Significance      1.9400  1.847737  1.604981  2.319975  2.159381   \n",
       "\n",
       "              Mid-P r* Wald  Mid-P r* score  \n",
       "p-value            0.027993        0.005342  \n",
       "Significance       1.911152        2.552854  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a table of the results...\n",
    "\n",
    "data_sf = {'True value': [0.0264, 1.94], 'r': [r_sf, r], 'r* Wald': [r_star_sf, r_s], 'r* score': [r_stars_sf, r_ss], \n",
    "        'Mid-P r': [r_sf_mp, r_mp], 'Mid-P r* Wald': [r_star_sf_mp, r_s_mp], 'Mid-P r* score': [r_stars_sf_mp, r_ss_mp]}\n",
    "df= pd.DataFrame(data_sf)\n",
    "df.index = ['p-value', 'Significance']\n",
    "\n",
    "df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Higher order density approximations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better results we need to go to higher order approximations of the asymptotic, which means modifying Eq. (1) wrt to these values for $q$:\n",
    "$$\n",
    "q_1 = \\frac{|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)|}{|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{bb}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "where $|\\cdot|$ denotes the determinant, and we are using the notation\n",
    "$$\n",
    "\\ell_{;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial X}\\Big|_{\\theta=Z}\\quad\\text{and}\\qquad \\ell_{Y;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial Y\\partial X^T}\\Big|_{\\theta=Z}\n",
    "$$\n",
    "with $\\theta=(\\mu,b)$ as a shorthand notation and where $\\hat\\theta = (\\hat\\mu,\\hat b)$ and $\\hat\\theta_\\psi = (\\mu, \\hat{\\hat b})$\n",
    "\n",
    "\n",
    "\n",
    "**Alternatively** we could use\n",
    "$$\n",
    "q_2 = \\frac{|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)|}{|\\varphi_{\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{\\lambda\\lambda}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "which uses the canonical parameter, $\\varphi$, of the tangent exponential model (TEM). Meaning that we have to transform our likelihood. Which is undesirable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculations to get the final result...** $q_1$ Edition\n",
    "Before anything we have to transform the log-likelihood $\\ell(\\theta,y)$ to be a function of the MLE's and some ancilliary statistics $\\ell(\\theta;\\hat\\theta,a)$. We repeat the log-likelhood\n",
    "$$\n",
    "\\ell(\\theta,y) =  -(\\mu+b)+y\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-b_0}{\\sigma_b}\\right)^2\n",
    "$$\n",
    "We know from the MLEs that we have\n",
    "$$\n",
    "\\hat\\mu = y-b_0,\\quad\\text{and}\\qquad \\hat b =b_0\n",
    "$$\n",
    "meaning that we can rewrite\n",
    "$$\n",
    "y = \\hat\\mu+\\hat b \n",
    "$$\n",
    "***which is what we expect when $y$ is from a Poisson counting experiment***, additionally we can in this example find the simplest ancilliary statistic choice by setting\n",
    "$$\n",
    "a=y-(\\hat\\mu+\\hat b) = 0\n",
    "$$\n",
    "Thus we can rewrite the log-likelihood to\n",
    "$$\n",
    "\\ell(\\theta;\\hat\\theta,a) =  -(\\mu+b)+(\\hat\\mu + \\hat b +a)\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat{b}}{\\sigma_b}\\right)^2\n",
    "$$\n",
    "or since we know $a$\n",
    "$$\n",
    "\\boxed{\\ell(\\theta;\\hat\\theta,a) =  -(\\mu+b)+(\\hat\\mu + \\hat b)\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat{b}}{\\sigma_b}\\right)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\hat\\mu}\\left( -(\\mu+b)+(\\hat\\mu+\\hat{b})\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat{b}}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0} = \\log(\\mu+b)\\Big|_{\\mu=y-b_0,b=b_0} = \\log y\n",
    "$$\n",
    "Similarly for $b$ we have\n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\hat\\mu}\\left( -(\\mu+b)+(\\hat\\mu+\\hat b)\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat b}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0} = \\log(\\mu+b) + \\frac{b-\\hat b}{\\sigma_b^2}\\Big|_{\\mu=y-b_0,b=b_0} = \\log(y)\n",
    "$$\n",
    "Giving \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\log y\\\\ \\log y\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "using the previous results we get \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\log(\\mu+\\hat{\\hat b})\\\\  \\log(\\mu+\\hat{\\hat b}) +\\frac{\\hat{\\hat b}-\\hat{b}}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Calculating $\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\hat\\mu^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "Using the previous results, we have that \n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\log(\\mu+b)\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\mu + b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\mu + \\hat{\\hat b}}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\log(\\mu+b) +\\frac{b-\\hat b}{\\sigma_b^2}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\mu + \\hat{\\hat b}} + \\frac{1}{\\sigma_b^2}\n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\boxed{\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{1}{\\mu + \\hat{\\hat b}}\\\\  \\frac{1}{\\mu + \\hat{\\hat b}} + \\frac{1}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating $\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial\\mu\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "We almost have all of these terms! Starting by finding the easiest term\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{\\mu+b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{y}\n",
    "$$\n",
    "Next we gotta find\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{\\mu+b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{y}\n",
    "$$\n",
    "Such that we have\n",
    "$$\n",
    "\\boxed{\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{1}{y} &\n",
    "\\frac{1}{y}\\\\\n",
    "\\frac{1}{y} &\n",
    "\\frac{1}{y} + \\frac{1}{\\sigma_b^2}\\end{pmatrix} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Jacobian temrs**\n",
    "Lastly we have the Jacobian terms. Where we can identify that\n",
    "$$\n",
    "j_{\\theta\\theta}(\\hat\\theta) = -\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) \n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\Rightarrow |j_{\\theta\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n",
    "\n",
    "The other term we already have, it just has to be evaluated for other values:\n",
    "$$\n",
    "j_{bb}(\\hat\\theta_\\psi) =  -\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial b^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}  = \\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating the determinants**\n",
    "Lastly comes the tedious part of calculating the determinant of the matrices we will get. First we have\n",
    "$$\n",
    "|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)| = \n",
    "\\left|\\begin{vmatrix}\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) &\n",
    "\\frac{1}{\\mu + \\hat{\\hat b}}\\\\  \n",
    "\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) - \\frac{\\hat{\\hat b}-\\hat{b}}{\\sigma_b^2}&\n",
    "\\frac{1}{\\mu + \\hat{\\hat b}} + \\frac{1}{\\sigma_b^2} \\end{vmatrix}\\right| = \\left| \\frac{\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right)}{\\sigma_b^2} - \\frac{(\\hat{\\hat b}-\\hat{b})}{(\\mu + \\hat{\\hat b})\\sigma_b^2} \\right|\n",
    "$$\n",
    "and\n",
    "$$\n",
    "|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "We now have a formula for the higher order approximation\n",
    "$$\n",
    "q_1 = \\left| y\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) - y\\frac{(\\hat{\\hat b}-\\hat{b})}{\\mu + \\hat{\\hat b}} \\right|\n",
    "\\left[\\frac{\\frac{1}{y\\sigma_b^2}}{\\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}}\\right]^{1/2}\n",
    "$$\n",
    "So now we can test this result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_order_terms(mu, b_hat, b_hhat, y, db):\n",
    "        q = np.abs(np.log(y/(mu+b_hhat))*y -y*(b_hhat-b_hat)/((mu+b_hhat)))\n",
    "        jacobian = np.sqrt(  np.abs(1/(y*db**2)) / np.abs(1/db**2 + (y/(mu+b_hhat)**2)))\n",
    "        return q*jacobian\n",
    "\n",
    "def modified_likelihood_root_HO(mu, mu_hat, b_hat, b_hhat, y, b_0, db):\n",
    "        r_mu = likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db)\n",
    "        q_1 = higher_order_terms(mu, b_hat, b_hhat, y, db)\n",
    "        return r_mu + (1 / r_mu) * np.log(q_1 / r_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True value</th>\n",
       "      <th>r</th>\n",
       "      <th>r*</th>\n",
       "      <th>r* H.O.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.031624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Significance</th>\n",
       "      <td>1.9400</td>\n",
       "      <td>1.847737</td>\n",
       "      <td>1.604981</td>\n",
       "      <td>1.857450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              True value         r        r*   r* H.O.\n",
       "p-value           0.0264  0.032320  0.054249  0.031624\n",
       "Significance      1.9400  1.847737  1.604981  1.857450"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_HO = modified_likelihood_root_HO(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO = stats.norm.sf(r_s_HO, loc=0)\n",
    "\n",
    "#Making a table of the results...\n",
    "\n",
    "data_sf = {'True value': [0.0264, 1.94], 'r': [r_sf, r], 'r*': [r_star_sf, r_s], 'r* H.O.': [r_sf_HO, r_s_HO]}\n",
    "df= pd.DataFrame(data_sf)\n",
    "df.index = ['p-value', 'Significance']\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing the canonical parameter**\n",
    "As briefly mentioned, there is an alternative way of calculating this, we have\n",
    "$$\n",
    "q_2 = \\frac{|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)|}{|\\varphi_{\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{\\lambda\\lambda}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "where we use the canonical parameter $\\varphi$ instead. So now we try to find it!\n",
    "To recapitulate a bit, we have the transformed log-likelihood\n",
    "\\begin{equation}\n",
    "\\ell(\\theta;\\hat\\theta,a) =  -(\\mu+b)+(\\hat\\mu + \\hat b)\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat{b}}{\\sigma_b}\\right)^2\n",
    "\\end{equation}\n",
    "For higher-order asymptotics, one often rewrites the log-likelihood as\n",
    "$$\n",
    "\\ell(\\theta;\\hat\\theta,a) =  \\varphi(\\theta)^Ts(y)-h(\\theta)+c(y)\n",
    "$$\n",
    "where $\\varphi(\\theta)$ is the **canonical parameter** that we are interested in, $s(y)$ is a *sufficient statistic*, $h(\\theta)$ captures additional terms dependent on $\\theta$, and $c(y)$ is a term independent of $\\theta$, that usually is ignored in inference. \n",
    "\n",
    "Eq(1) suggests that \n",
    "$$\n",
    "\\varphi(\\mu,b) = \\ln(\\mu+b)\n",
    "$$ is a good canonical parameter, since $s(y)=y=\\hat\\mu+\\hat b+ a$ follows this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding remaining parts\n",
    "From this it is trivial to find that\n",
    "$$\n",
    "\\varphi_\\theta(\\hat{\\theta}) = \\begin{pmatrix} \\frac{\\partial\\varphi}{\\partial\\mu}\\Big|_{\\theta=\\hat\\theta}\\\\\n",
    "\\frac{\\partial\\varphi}{\\partial b}\\Big|_{\\theta=\\hat\\theta}\\end{pmatrix}\n",
    "= \\begin{pmatrix} \\frac{1}{\\hat\\mu+\\hat b}\\\\\\frac{1}{\\hat\\mu+\\hat b}\\end{pmatrix}\n",
    "= \\begin{pmatrix} \\frac{1}{y}\\\\\\frac{1}{y}\\end{pmatrix}\n",
    "$$\n",
    "and even easier now to see that\n",
    "$$\n",
    "\\varphi_\\lambda(\\hat\\theta_\\psi) = \\frac{1}{\\mu+\\hat{\\hat b}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all togheter\n",
    "That means that we now have\n",
    "$$\n",
    "|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)| = \\begin{vmatrix}\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right)& \\frac{1}{\\mu+\\hat{\\hat b}}\\end{vmatrix}\n",
    "$$\n",
    "were we now note that $|\\cdot|$ is no longer the determinant, but rather the Euclidian norm. This yields\n",
    "$$\n",
    "|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)| = \\sqrt{\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right)^2 + \\frac{1}{(\\mu+\\hat{\\hat b})^2}}\n",
    "$$\n",
    "Similarly we have\n",
    "$$\n",
    "\\varphi_\\theta(\\hat\\theta) = \\frac{\\sqrt{2}}{y^2}\n",
    "$$\n",
    "The fisher information term remains the same as for $q_1$ meaning that we have\n",
    "$$\n",
    "q_2 = \\frac{y^2\\sqrt{\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right)^2 + \\frac{1}{(\\mu+\\hat{\\hat b})^2}}}{\\sqrt{2}}\\left[\\frac{\\frac{1}{y\\sigma_b^2}}{\\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}}\\right]^{1/2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_order_terms_2(mu, b_hhat, y, db):\n",
    "        numerator = y**2*np.sqrt(np.log(y/(mu+b_hhat))**2 + 1/(mu+b_hhat)**2 )\n",
    "        denominator = np.sqrt(2)\n",
    "        q = numerator/denominator\n",
    "        jacobian = np.sqrt(  np.abs(1/(y*db**2)) / np.abs(1/db**2 + (y/(mu+b_hhat)**2)))\n",
    "        return q*jacobian\n",
    "\n",
    "def modified_likelihood_root_HO_2(mu, mu_hat, b_hat, b_hhat, y, b_0, db):\n",
    "        r_mu = likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db)\n",
    "        q_2 = higher_order_terms_2(mu, b_hhat, y, db)\n",
    "        return r_mu + (1 / r_mu) * np.log(q_2 / r_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True value</th>\n",
       "      <th>r</th>\n",
       "      <th>r*</th>\n",
       "      <th>r* H.O.</th>\n",
       "      <th>r* H.O. canon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.031624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Significance</th>\n",
       "      <td>1.9400</td>\n",
       "      <td>1.847737</td>\n",
       "      <td>1.604981</td>\n",
       "      <td>1.857450</td>\n",
       "      <td>2.475407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              True value         r        r*   r* H.O.  r* H.O. canon\n",
       "p-value           0.0264  0.032320  0.054249  0.031624       0.031624\n",
       "Significance      1.9400  1.847737  1.604981  1.857450       2.475407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_HO2 = modified_likelihood_root_HO_2(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO2 = stats.norm.sf(r_s_HO, loc=0)\n",
    "\n",
    "#Making a table of the results...\n",
    "\n",
    "data_sf = {'True value': [0.0264, 1.94],'r': [r_sf, r], 'r*': [r_star_sf, r_s], 'r* H.O.': [r_sf_HO, r_s_HO], 'r* H.O. canon': [r_sf_HO2, r_s_HO2]}\n",
    "df= pd.DataFrame(data_sf)\n",
    "df.index = ['p-value', 'Significance']\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that using $q_1$ yields a somewhat higher significance than just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD TESTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Higher order density approximations**  WRONG TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better results we need to go to higher order approximations of the asymptotic, which means modifying Eq. (1) wrt to these values for $q$:\n",
    "$$\n",
    "q_1 = \\frac{|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)|}{|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{bb}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "where $|\\cdot|$ denotes the determinant, and we are using the notation\n",
    "$$\n",
    "\\ell_{;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial X}\\Big|_{\\theta=Z}\\quad\\text{and}\\qquad \\ell_{Y;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial Y\\partial X^T}\\Big|_{\\theta=Z}\n",
    "$$\n",
    "with $\\theta=(\\mu,b)$ as a shorthand notation and where $\\hat\\theta = (\\hat\\mu,\\hat b)$ and $\\hat\\theta_\\psi = (\\mu, \\hat{\\hat b})$\n",
    "\n",
    "\n",
    "\n",
    "**Alternatively** we could use\n",
    "$$\n",
    "q_2 = \\frac{|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)|}{|\\varphi_{\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{\\lambda\\lambda}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "which uses the canonical parameter, $\\varphi$, of the tangent exponential model (TEM). Meaning that we have to transform our likelihood. Which is undesirable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculations to get the final result...**\n",
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\hat\\mu}\\left( -(\\mu+b)+y\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-b_0}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0}\n",
    "$$\n",
    "substituting $y=\\hat\\mu +b_0$ we get\n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\hat\\mu}\\left( -(\\mu+b)+(\\hat\\mu+b_0)\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-b_0}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0} = \\log(\\mu+b)\\Big|_{\\mu=y-b_0,b=b_0} = \\log y\n",
    "$$\n",
    "Similarly for $\\hat b$ we have\n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\hat\\mu}\\left( -(\\mu+b)+y\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-\\hat b}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{b-\\hat b}{\\sigma_b^2}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{b_0-b_0}{\\sigma_b^2}=0\n",
    "$$\n",
    "Giving \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\log y\\\\ 0\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "using the previous results we get \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\log(\\mu+\\hat{\\hat b})\\\\  \\frac{\\hat{\\hat b}-\\hat{b}}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Calculating $\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\hat\\mu^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "Using the previous results, we have that \n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\log(\\mu+b)\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\mu + b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\mu + \\hat{\\hat b}}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial\\hat b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\frac{b-\\hat b}{\\sigma_b^2}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{1}{\\sigma_b^2}\n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\boxed{\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{1}{\\mu + \\hat{\\hat b}}\\\\  \\frac{1}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating $\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial\\mu\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "We almost have all of these terms! Starting by finding the easiest term\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat b}\\Big|_{\\mu=y-b_0,b=b_0} = 0\n",
    "$$\n",
    "Next we gotta find\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\hat\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{\\mu+b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{1}{y}\n",
    "$$\n",
    "Such that we have\n",
    "$$\n",
    "\\boxed{\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{1}{y} &\n",
    "\\frac{1}{y}\\\\\n",
    "0 &\n",
    "\\frac{1}{\\sigma_b^2}\\end{pmatrix} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Jacobian temrs**\n",
    "Lastly we have the Jacobian terms. Where we can identify that\n",
    "$$\n",
    "j_{\\theta\\theta}(\\hat\\theta) = -\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) \n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\Rightarrow |j_{\\theta\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n",
    "\n",
    "The other term we already have, it just has to be evaluated for other values:\n",
    "$$\n",
    "j_{bb}(\\hat\\theta_\\psi) =  -\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial b^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}  = \\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating the determinants**\n",
    "Lastly comes the tedious part of calculating the determinant of the matrices we will get. First we have\n",
    "$$\n",
    "|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)| = \n",
    "\\left|\\begin{vmatrix}\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) &\n",
    "\\frac{1}{\\mu + \\hat{\\hat b}}\\\\  \n",
    "-\\frac{b-\\hat{\\hat b}}{\\sigma_b^2}& \n",
    "\\frac{1}{\\sigma_b^2} \\end{vmatrix}\\right| = \\frac{\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right)}{\\sigma_b^2} + \\frac{(b-\\hat{\\hat b})}{(\\mu + \\hat{\\hat b})\\sigma_b^2} \n",
    "$$\n",
    "and\n",
    "$$\n",
    "|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "We now have a formula for the higher order approximation\n",
    "$$\n",
    "q_1 = \\left|-y\\left((\\hat{\\hat b}-\\hat{b})\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) + \\frac{1}{\\mu + \\hat{\\hat b}}\\right)\\right|\\left[\\frac{\\frac{1}{y\\sigma_b^2}}{\\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}}\\right]^{1/2}\n",
    "$$\n",
    "So now we can test this result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higher_order_terms(mu, b_hat, b_hhat, y, db):\n",
    "        q = np.abs(-y*( (b_hhat - b_hat)*np.log( y/(mu+b_hhat) ) + 1/(mu+b_hhat) ))\n",
    "        jacobian = np.sqrt(  (1/(y*db**2)) / (1/db**2 + (y/(mu+b_hhat)**2)))\n",
    "        return q*jacobian\n",
    "\n",
    "def modified_likelihood_root_HO(mu, mu_hat, b_hat, b_hhat, y, b_0, db):\n",
    "        r_mu = likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db)\n",
    "        q_1 = higher_order_terms(mu, b_hat, b_hhat, y, db)\n",
    "        return r_mu + (1 / r_mu) * np.log(q_1 / r_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>r*</th>\n",
       "      <th>r* H.O.</th>\n",
       "      <th>Mid-P r* H.O.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.014409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Significance</th>\n",
       "      <td>1.847737</td>\n",
       "      <td>1.604981</td>\n",
       "      <td>1.905583</td>\n",
       "      <td>2.185969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     r        r*   r* H.O.  Mid-P r* H.O.\n",
       "p-value       0.032320  0.054249  0.028352       0.014409\n",
       "Significance  1.847737  1.604981  1.905583       2.185969"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_s_HO = modified_likelihood_root_HO(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO = stats.norm.sf(r_s_HO, loc=0)\n",
    "\n",
    "\n",
    "y_obs_mp = 3.5\n",
    "mu_hat_mp = y_obs_mp - b_0\n",
    "b_hatt_mp = (b_0-sigma_b**2+np.sqrt((b_0-sigma_b**2)**2+4*y_obs_mp*(sigma_b**2)))/2\n",
    "\n",
    "r_s_HO_mp = modified_likelihood_root_HO(0, mu_hat_mp, b_hat, b_hatt_mp, y_obs_mp, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO_mp = stats.norm.sf(r_s_HO_mp, loc=0)\n",
    "\n",
    "#Making a table of the results...\n",
    "\n",
    "data_sf = {'r': [r_sf, r], 'r*': [r_star_sf, r_s], 'r* H.O.': [r_sf_HO, r_s_HO], 'Mid-P r* H.O.': [r_sf_HO_mp, r_s_HO_mp]}\n",
    "df= pd.DataFrame(data_sf)\n",
    "df.index = ['p-value', 'Significance']\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Higher order density approximations**  WRONG DERIVATIONS (JUST TO TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better results we need to go to higher order approximations of the asymptotic, which means modifying Eq. (1) wrt to these values for $q$:\n",
    "$$\n",
    "q_1 = \\frac{|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)|}{|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{bb}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "where $|\\cdot|$ denotes the determinant, and we are using the notation\n",
    "$$\n",
    "\\ell_{;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial X}\\Big|_{\\theta=Z}\\quad\\text{and}\\qquad \\ell_{Y;X}(Z) = \\frac{\\partial\\ell(\\theta)}{\\partial Y\\partial X^T}\\Big|_{\\theta=Z}\n",
    "$$\n",
    "with $\\theta=(\\mu,b)$ as a shorthand notation and where $\\hat\\theta = (\\hat\\mu,\\hat b)$ and $\\hat\\theta_\\psi = (\\mu, \\hat{\\hat b})$\n",
    "\n",
    "\n",
    "\n",
    "**Alternatively** we could use\n",
    "$$\n",
    "q_2 = \\frac{|\\varphi(\\hat\\theta) - \\varphi(\\hat\\theta_\\psi) \\qquad \\varphi_{\\lambda}(\\hat\\theta_\\psi)|}{|\\varphi_{\\theta}(\\hat\\theta)|}\\left\\{\\frac{|j_{\\theta\\theta}(\\hat{\\theta})|}{|j_{\\lambda\\lambda}(\\hat{\\theta}_\\psi)|}\\right\\}^{1/2}\n",
    "$$\n",
    "which uses the canonical parameter, $\\varphi$, of the tangent exponential model (TEM). Meaning that we have to transform our likelihood. Which is undesirable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Calculations to get the final result...**\n",
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial\\mu}\\left( -(\\mu+b)+y\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-b_0}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0}\n",
    "$$\n",
    "giving\n",
    "$$\n",
    "-1 +\\frac{y}{\\hat\\mu+\\hat b} = 0\n",
    "$$\n",
    "Similarly for $\\hat b$ we have\n",
    "$$\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial b}\\left( -(\\mu+b)+y\\ln(\\mu+b) -\\frac{1}{2}\\left(\\frac{b-b_0}{\\sigma_b}\\right)^2\\right)\\Big|_{\\mu=y-b_0,b=b_0} = -1 +\\frac{y}{\\hat\\mu+\\hat b} - \\frac{\\hat b-b_0}{\\sigma_b^2}\\Big|_{\\mu=y-b_0,b=b_0} =0\n",
    "$$\n",
    "Giving \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} 0\\\\ 0\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Calculating $\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial\\ell(\\mu,b)}{\\partial\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial\\ell(\\mu,b)}{\\partial b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "using the previous results we get \n",
    "$$\n",
    "\\boxed{\\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} -1 +\\frac{y}{\\mu+\\hat{\\hat b}}\\\\  -1 +\\frac{y}{\\hat\\mu+\\hat{\\hat b}} - \\frac{\\hat{\\hat b}-b_0}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **Calculating $\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)$**\n",
    "Next we have that\n",
    "$$\n",
    "\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\mu^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial b^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}\\end{pmatrix}\n",
    "$$\n",
    "Using the previous results, we have that \n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial\\mu}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\left(-1 +\\frac{y}{\\mu+b} \\right)\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = -\\frac{y}{(\\mu + b)^2}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = -\\frac{y}{(\\mu+\\hat{\\hat b})^2}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b}\\frac{\\partial\\ell(\\mu,b)}{\\partial b}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = \\frac{\\partial}{\\partial b}\\left(-1 +\\frac{y}{\\mu+b} - \\frac{ b-b_0}{\\sigma_b^2}\\right)\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}} = -\\frac{y}{(\\mu+\\hat{\\hat b})^2} -\\frac{1}{\\sigma_b^2}\n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\boxed{\\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi) = \\begin{pmatrix} -\\frac{y}{(\\mu+\\hat{\\hat b})^2}\\\\  -\\frac{y}{(\\mu+\\hat{\\hat b})^2} -\\frac{1}{\\sigma_b^2}\\end{pmatrix}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating $\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)$**\n",
    "Starting the calculations... we have first that\n",
    "$$\n",
    "\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} \\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\mu}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b \\partial\\mu}\\Big|_{\\mu=y-b_0,b=b_0}\\\\\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial\\mu\\partial b}\\Big|_{\\mu=y-b_0,b=b_0} &\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial b}\\Big|_{\\mu=y-b_0,b=b_0}\\end{pmatrix}\n",
    "$$\n",
    "We almost have all of these terms! Starting by finding the easiest term\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial b}\\Big|_{\\mu=y-b_0,b=b_0} = \\frac{\\partial}{\\partial \\mu}\\left(-1 +\\frac{y}{\\mu+b} \\right)\\Big|_{\\mu=\\hat\\mu,b=\\hat{b}} = -\\frac{1}{y} \n",
    "$$\n",
    "Next we gotta find\n",
    "$$\n",
    "\\frac{\\partial^2\\ell(\\mu,b)}{\\partial \\mu \\partial\\mu}\\Big|_{\\mu=y-b_0,b=b_0} = -\\frac{y}{(\\mu+b)^2}\\Big|_{\\mu=y-b_0,b=b_0} = -\\frac{1}{y}\n",
    "$$\n",
    "Such that we have\n",
    "$$\n",
    "\\boxed{\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) = \\begin{pmatrix} -\\frac{1}{y} &\n",
    "-\\frac{1}{y}\\\\\n",
    "-\\frac{1}{y} &\n",
    "-\\frac{1}{y} -\\frac{1}{\\sigma_b^2}\\end{pmatrix} }\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Jacobian temrs**\n",
    "Lastly we have the Jacobian terms. Where we can identify that\n",
    "$$\n",
    "j_{\\theta\\theta}(\\hat\\theta) = -\\ell_{\\theta;\\hat\\theta}(\\hat\\theta) \n",
    "$$\n",
    "giving\n",
    "$$\n",
    "\\Rightarrow |j_{\\theta\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n",
    "\n",
    "The other term we already have, it just has to be evaluated for other values:\n",
    "$$\n",
    "j_{bb}(\\hat\\theta_\\psi) =  -\\frac{\\partial^2\\ell(\\mu,b)}{\\partial b\\partial b^T}\\Big|_{\\mu=\\mu,b=\\hat{\\hat b}}  = \\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating the determinants**\n",
    "Lastly comes the tedious part of calculating the determinant of the matrices we will get. First we have\n",
    "$$\n",
    "|\\ell_{;\\hat\\theta}(\\hat\\theta) - \\ell_{;\\hat\\theta}(\\hat\\theta_\\psi) \\qquad \\ell_{b;\\hat\\theta}(\\hat\\theta_\\psi)| = \n",
    "\\left|\\begin{pmatrix} 1 -\\frac{y}{\\mu+\\hat{\\hat b}}&\n",
    " -\\frac{y}{(\\mu+\\hat{\\hat b})^2}\\\\\n",
    "1 -\\frac{y}{\\mu+\\hat{\\hat b}} &\n",
    "-\\frac{y}{(\\mu+\\hat{\\hat b})^2} -\\frac{1}{\\sigma_b^2} \\end{pmatrix}\\right| =\\frac{\\mu+\\hat{\\hat b}-y}{(\\mu+\\hat{\\hat b})\\sigma_b^2}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "|\\ell_{\\theta;\\hat\\theta}(\\hat\\theta)| = \\frac{1}{y\\sigma_b^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Putting it all together\n",
    "We now have a formula for the higher order approximation\n",
    "$$\n",
    "q_1 = \\left|-y\\left((\\hat{\\hat b}-\\hat{b})\\log\\left(\\frac{y}{\\mu+\\hat{\\hat b}}\\right) + \\frac{1}{\\mu + \\hat{\\hat b}}\\right)\\right|\\left[\\frac{\\frac{1}{y\\sigma_b^2}}{\\frac{y}{(\\mu+\\hat{\\hat b})^2} + \\frac{1}{\\sigma_b^2}}\\right]^{1/2}\n",
    "$$\n",
    "So now we can test this result!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.458416794992058\n",
      "10.469399415624396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>r*</th>\n",
       "      <th>r* H.O.</th>\n",
       "      <th>Mid-P r* H.O.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>0.032320</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Significance</th>\n",
       "      <td>1.847737</td>\n",
       "      <td>1.604981</td>\n",
       "      <td>2.272263</td>\n",
       "      <td>2.578139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     r        r*   r* H.O.  Mid-P r* H.O.\n",
       "p-value       0.032320  0.054249  0.011535       0.004967\n",
       "Significance  1.847737  1.604981  2.272263       2.578139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def higher_order_terms(mu, b_hhat, y, db):\n",
    "        numerator = np.abs((mu+b_hhat-y)/((mu+b_hhat)*db**2))\n",
    "        denoninator = np.abs(1/(y*db**2))\n",
    "        q = numerator/denoninator\n",
    "        print(q)\n",
    "        jacobian = np.sqrt(  np.abs((1/(y*db**2))) / np.abs(1/db**2 + (y/(mu+b_hhat)**2)))\n",
    "        return q*jacobian\n",
    "\n",
    "def modified_likelihood_root_HO(mu, mu_hat, b_hat, b_hhat, y, b_0, db):\n",
    "        r_mu = likelihood_root(mu, mu_hat, b_hat, b_hhat, y, b_0, db)\n",
    "        q_1 = higher_order_terms(mu, b_hhat, y, db)\n",
    "        return r_mu + (1 / r_mu) * np.log(q_1 / r_mu)\n",
    "\n",
    "r_s_HO = modified_likelihood_root_HO(0, mu_hat, b_hat, b_hatt, y_obs, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO = stats.norm.sf(r_s_HO, loc=0)\n",
    "\n",
    "\n",
    "y_obs_mp = 3.5\n",
    "mu_hat_mp = y_obs_mp - b_0\n",
    "b_hatt_mp = (b_0-sigma_b**2+np.sqrt((b_0-sigma_b**2)**2+4*y_obs_mp*(sigma_b**2)))/2\n",
    "\n",
    "r_s_HO_mp = modified_likelihood_root_HO(0, mu_hat_mp, b_hat, b_hatt_mp, y_obs_mp, b_0, sigma_b)\n",
    "\n",
    "r_sf_HO_mp = stats.norm.sf(r_s_HO_mp, loc=0)\n",
    "\n",
    "#Making a table of the results...\n",
    "\n",
    "data_sf = {'r': [r_sf, r], 'r*': [r_star_sf, r_s], 'r* H.O.': [r_sf_HO, r_s_HO], 'Mid-P r* H.O.': [r_sf_HO_mp, r_s_HO_mp]}\n",
    "df= pd.DataFrame(data_sf)\n",
    "df.index = ['p-value', 'Significance']\n",
    "\n",
    "df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HODA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
